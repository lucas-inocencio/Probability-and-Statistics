{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         date_hour  bytes_up  bytes_down\n",
       " 0               15  5.123633    6.449962\n",
       " 1               15  5.063598    6.354955\n",
       " 2               15  5.057019    6.363475\n",
       " 3               15  4.987535    6.302449\n",
       " 4               15  4.597361    5.906413\n",
       " ...            ...       ...         ...\n",
       " 4417898         23  0.903090    0.903090\n",
       " 4417899         23  0.903090    0.903090\n",
       " 4417900         23  0.903090    0.903090\n",
       " 4417901         23  0.903090    0.903090\n",
       " 4417902         23  0.903090    1.505150\n",
       " \n",
       " [4417903 rows x 3 columns],\n",
       "          date_hour  bytes_up  bytes_down\n",
       " 0                0  3.475238    4.691839\n",
       " 1                0  2.836283    2.516215\n",
       " 2                0  3.652624    4.578800\n",
       " 3                0  2.889936    2.360215\n",
       " 4                0  3.488736    4.713127\n",
       " ...            ...       ...         ...\n",
       " 1620524         16  3.306211    4.637810\n",
       " 1620525         16  3.850524    3.201943\n",
       " 1620526         16  2.688420    4.695762\n",
       " 1620527         16  0.000000    2.133539\n",
       " 1620528         16  0.000000    1.982271\n",
       " \n",
       " [1620529 rows x 3 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sturges(data): \n",
    "    return int((1 + 3.3 * np.log10(len(data))))\n",
    "\n",
    "df_smart_tv = pd.read_csv('dataset_smart-tv.csv', usecols = ['date_hour','bytes_up', 'bytes_down'])\n",
    "df_chromecast = pd.read_csv('dataset_chromecast.csv', usecols = ['date_hour','bytes_up', 'bytes_down'])\n",
    "\n",
    "df_smart_tv = pd.concat([df_smart_tv[\"date_hour\"], np.log10(df_smart_tv[['bytes_up', 'bytes_down']].replace(0, np.nan))], axis=1)\n",
    "df_chromecast = pd.concat([df_chromecast[\"date_hour\"], np.log10(df_chromecast[['bytes_up', 'bytes_down']].replace(0, np.nan))], axis=1)\n",
    "\n",
    "df_smart_tv = df_smart_tv.replace(np.nan, 0)\n",
    "df_chromecast = df_chromecast.replace(np.nan, 0)\n",
    "\n",
    "values = df_smart_tv[\"date_hour\"]\n",
    "converted_values = []\n",
    "for x in values:\n",
    "    try:\n",
    "        converted_values += [datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour]\n",
    "    except:\n",
    "        converted_values += [x]\n",
    "\n",
    "df_smart_tv[\"date_hour\"] = converted_values\n",
    "\n",
    "values = df_chromecast[\"date_hour\"]\n",
    "converted_values = []\n",
    "for x in values:\n",
    "    try:\n",
    "        converted_values += [datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour]\n",
    "    except:\n",
    "        converted_values += [x]\n",
    "\n",
    "df_chromecast[\"date_hour\"] = converted_values\n",
    "\n",
    "df_smart_tv, df_chromecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9217860533606511,\n",
       " 0.9217860533606511,\n",
       " 0.788016532974326,\n",
       " -8.641330879619121e-16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data_set_1 = df_smart_tv.groupby(\"date_hour\")[\"bytes_up\"].median().argmax()\n",
    "data_set_2 = df_smart_tv.groupby(\"date_hour\")[\"bytes_up\"].mean().argmax()\n",
    "data_set_3 = df_smart_tv.groupby(\"date_hour\")[\"bytes_down\"].median().argmax()\n",
    "data_set_4 = df_smart_tv.groupby(\"date_hour\")[\"bytes_down\"].mean().argmax()\n",
    "data_set_5 = df_chromecast.groupby(\"date_hour\")[\"bytes_up\"].median().argmax()\n",
    "data_set_6 = df_chromecast.groupby(\"date_hour\")[\"bytes_up\"].mean().argmax()\n",
    "data_set_7 = df_chromecast.groupby(\"date_hour\")[\"bytes_down\"].median().argmax()\n",
    "data_set_8 = df_chromecast.groupby(\"date_hour\")[\"bytes_down\"].mean().argmax()\n",
    "\n",
    "ds_1 = df_smart_tv.query('date_hour == @data_set_1')['bytes_up']\n",
    "ds_2 = df_smart_tv.query('date_hour == @data_set_2')['bytes_up']\n",
    "ds_3 = df_smart_tv.query('date_hour == @data_set_3')['bytes_down']\n",
    "ds_4 = df_smart_tv.query('date_hour == @data_set_4')['bytes_down']\n",
    "ds_5 = df_chromecast.query('date_hour == @data_set_5')['bytes_up']\n",
    "ds_6 = df_chromecast.query('date_hour == @data_set_6')['bytes_up']\n",
    "ds_7 = df_chromecast.query('date_hour == @data_set_7')['bytes_down']\n",
    "ds_8 = df_chromecast.query('date_hour == @data_set_8')['bytes_down']\n",
    "\n",
    "\n",
    "obs_1 = pd.cut(ds_1, bins=sturges(ds_1), include_lowest=True)\n",
    "obs_3 = pd.cut(ds_3, bins=sturges(ds_1), include_lowest=True)\n",
    "\n",
    "obs_1 = obs_1.value_counts().sort_index()/obs_1.value_counts().sort_index().sum()\n",
    "obs_3 = obs_3.value_counts().sort_index()/obs_3.value_counts().sort_index().sum()\n",
    "\n",
    "g1, p, dof, expctd = chi2_contingency([obs_1, obs_3], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_2 = pd.cut(ds_2, bins=sturges(ds_2), include_lowest=True)\n",
    "obs_4 = pd.cut(ds_4, bins=sturges(ds_2), include_lowest=True)\n",
    "\n",
    "obs_2 = obs_2.value_counts().sort_index()/obs_2.value_counts().sort_index().sum()\n",
    "obs_4 = obs_4.value_counts().sort_index()/obs_4.value_counts().sort_index().sum()\n",
    "\n",
    "g2, p, dof, expctd = chi2_contingency([obs_2, obs_4], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_5 = pd.cut(ds_5, bins=sturges(ds_5), include_lowest=True)\n",
    "obs_7 = pd.cut(ds_7, bins=sturges(ds_5), include_lowest=True)\n",
    "\n",
    "obs_5 = obs_5.value_counts().sort_index()/obs_5.value_counts().sort_index().sum()\n",
    "obs_7 = obs_7.value_counts().sort_index()/obs_7.value_counts().sort_index().sum()\n",
    "\n",
    "g3, p, dof, expctd = chi2_contingency([obs_5, obs_7], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_6 = pd.cut(ds_6, bins=sturges(ds_6), include_lowest=True)\n",
    "obs_8 = pd.cut(ds_6, bins=sturges(ds_6), include_lowest=True)\n",
    "\n",
    "obs_6 = obs_6.value_counts().sort_index()/obs_6.value_counts().sort_index().sum()\n",
    "obs_8 = obs_8.value_counts().sort_index()/obs_8.value_counts().sort_index().sum()\n",
    "\n",
    "g4, p, dof, expctd = chi2_contingency([obs_6, obs_8], lambda_=\"log-likelihood\")\n",
    "\n",
    "g1, g2, g3, g4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37083a178839ddb6837eca99e3841ef7be6dad5dc50c6d19829e2187d61ddd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
