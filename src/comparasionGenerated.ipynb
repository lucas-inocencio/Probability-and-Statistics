{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         date_hour  bytes_up  bytes_down\n",
       " 0               15  5.123636    6.449963\n",
       " 1               15  5.063602    6.354955\n",
       " 2               15  5.057023    6.363475\n",
       " 3               15  4.987539    6.302449\n",
       " 4               15  4.597372    5.906413\n",
       " ...            ...       ...         ...\n",
       " 4417898         23  0.954243    0.954243\n",
       " 4417899         23  0.954243    0.954243\n",
       " 4417900         23  0.954243    0.954243\n",
       " 4417901         23  0.954243    0.954243\n",
       " 4417902         23  0.954243    1.518514\n",
       " \n",
       " [4417903 rows x 3 columns],\n",
       "          date_hour  bytes_up  bytes_down\n",
       " 0                0  3.475383    4.691848\n",
       " 1                0  2.836916    2.517536\n",
       " 2                0  3.652720    4.578812\n",
       " 3                0  2.890496    2.362105\n",
       " 4                0  3.488877    4.713136\n",
       " ...            ...       ...         ...\n",
       " 1620524         16  3.306425    4.637820\n",
       " 1620525         16  3.850585    3.202216\n",
       " 1620526         16  2.689309    4.695771\n",
       " 1620527         16  0.000000    2.136721\n",
       " 1620528         16  0.000000    1.986772\n",
       " \n",
       " [1620529 rows x 3 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sturges(data): \n",
    "    return int((1 + 3.3 * np.log10(len(data))))\n",
    "\n",
    "df_smart_tv = pd.read_csv('dataset_smart-tv.csv', usecols = ['date_hour','bytes_up', 'bytes_down'])\n",
    "df_chromecast = pd.read_csv('dataset_chromecast.csv', usecols = ['date_hour','bytes_up', 'bytes_down'])\n",
    "\n",
    "df_smart_tv[['bytes_up', 'bytes_down']] += 1\n",
    "df_chromecast[['bytes_up', 'bytes_down']] += 1\n",
    "\n",
    "df_smart_tv = pd.concat([df_smart_tv[\"date_hour\"], np.log10(df_smart_tv[['bytes_up', 'bytes_down']])], axis=1)\n",
    "df_chromecast = pd.concat([df_chromecast[\"date_hour\"], np.log10(df_chromecast[['bytes_up', 'bytes_down']])], axis=1)\n",
    "\n",
    "values = df_smart_tv[\"date_hour\"]\n",
    "converted_values = []\n",
    "for x in values:\n",
    "    try:\n",
    "        converted_values += [datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour]\n",
    "    except:\n",
    "        converted_values += [x]\n",
    "\n",
    "df_smart_tv[\"date_hour\"] = converted_values\n",
    "\n",
    "values = df_chromecast[\"date_hour\"]\n",
    "converted_values = []\n",
    "for x in values:\n",
    "    try:\n",
    "        converted_values += [datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour]\n",
    "    except:\n",
    "        converted_values += [x]\n",
    "\n",
    "df_chromecast[\"date_hour\"] = converted_values\n",
    "\n",
    "df_smart_tv, df_chromecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 16) (1335679469.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ds_5 = df_chromecast.query('date_hour == @data_set_7'')['bytes_up']\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 16)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data_set_1 = df_smart_tv.groupby(\"date_hour\")[\"bytes_up\"].median().argmax()\n",
    "data_set_2 = df_smart_tv.groupby(\"date_hour\")[\"bytes_up\"].mean().argmax()\n",
    "data_set_3 = df_smart_tv.groupby(\"date_hour\")[\"bytes_down\"].median().argmax()\n",
    "data_set_4 = df_smart_tv.groupby(\"date_hour\")[\"bytes_down\"].mean().argmax()\n",
    "data_set_5 = df_chromecast.groupby(\"date_hour\")[\"bytes_up\"].median().argmax()\n",
    "data_set_6 = df_chromecast.groupby(\"date_hour\")[\"bytes_up\"].mean().argmax()\n",
    "data_set_7 = df_chromecast.groupby(\"date_hour\")[\"bytes_down\"].median().argmax()\n",
    "data_set_8 = df_chromecast.groupby(\"date_hour\")[\"bytes_down\"].mean().argmax()\n",
    "\n",
    "ds_1 = df_smart_tv.query('date_hour == @data_set_1')['bytes_up']\n",
    "ds_2 = df_smart_tv.query('date_hour == @data_set_2')['bytes_up']\n",
    "ds_3 = df_smart_tv.query('date_hour == @data_set_3')['bytes_down']\n",
    "ds_4 = df_smart_tv.query('date_hour == @data_set_4')['bytes_down']\n",
    "ds_5 = df_chromecast.query('date_hour == @data_set_7')['bytes_up']\n",
    "ds_6 = df_chromecast.query('date_hour == @data_set_8')['bytes_up']\n",
    "ds_7 = df_chromecast.query('date_hour == @data_set_7')['bytes_down']\n",
    "ds_8 = df_chromecast.query('date_hour == @data_set_8')['bytes_down']\n",
    "\n",
    "\n",
    "obs_1 = pd.cut(ds_1, bins=sturges(ds_1), include_lowest=True)\n",
    "obs_3 = pd.cut(ds_3, bins=sturges(ds_1), include_lowest=True)\n",
    "\n",
    "obs_1 = obs_1.value_counts().sort_index()/obs_1.value_counts().sort_index().sum()\n",
    "obs_3 = obs_3.value_counts().sort_index()/obs_3.value_counts().sort_index().sum()\n",
    "\n",
    "g1, p, dof, expctd = chi2_contingency([obs_1, obs_3], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_2 = pd.cut(ds_2, bins=sturges(ds_2), include_lowest=True)\n",
    "obs_4 = pd.cut(ds_4, bins=sturges(ds_2), include_lowest=True)\n",
    "\n",
    "obs_2 = obs_2.value_counts().sort_index()/obs_2.value_counts().sort_index().sum()\n",
    "obs_4 = obs_4.value_counts().sort_index()/obs_4.value_counts().sort_index().sum()\n",
    "\n",
    "g2, p, dof, expctd = chi2_contingency([obs_2, obs_4], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_5 = pd.cut(ds_5, bins=sturges(ds_5), include_lowest=True)\n",
    "obs_7 = pd.cut(ds_7, bins=sturges(ds_5), include_lowest=True)\n",
    "\n",
    "obs_5 = obs_5.value_counts().sort_index()/obs_5.value_counts().sort_index().sum()\n",
    "obs_7 = obs_7.value_counts().sort_index()/obs_7.value_counts().sort_index().sum()\n",
    "\n",
    "g3, p, dof, expctd = chi2_contingency([obs_5, obs_7], lambda_=\"log-likelihood\")\n",
    "\n",
    "obs_6 = pd.cut(ds_6, bins=sturges(ds_6), include_lowest=True)\n",
    "obs_8 = pd.cut(ds_6, bins=sturges(ds_6), include_lowest=True)\n",
    "\n",
    "obs_6 = obs_6.value_counts().sort_index()/obs_6.value_counts().sort_index().sum()\n",
    "obs_8 = obs_8.value_counts().sort_index()/obs_8.value_counts().sort_index().sum()\n",
    "\n",
    "g4, p, dof, expctd = chi2_contingency([obs_6, obs_8], lambda_=\"log-likelihood\")\n",
    "\n",
    "g1, g2, g3, g4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37083a178839ddb6837eca99e3841ef7be6dad5dc50c6d19829e2187d61ddd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
